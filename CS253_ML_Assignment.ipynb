{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test1 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Party             23\n",
       "Criminal Case     35\n",
       "Total Assets     210\n",
       "Liabilities      170\n",
       "state             28\n",
       "Education         10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['ID','Candidate','Constituency ∇'],axis='columns',inplace=True)\n",
    "df_test.drop(['ID','Candidate','Constituency ∇'],axis='columns',inplace=True)\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_amount(amount_str):\n",
    "    if 'Crore' in amount_str:\n",
    "        cleaned_str = ''.join(filter(str.isdigit, amount_str))\n",
    "        amount_numeric = int(cleaned_str) * 10000000\n",
    "    elif 'Lac' in amount_str:\n",
    "        cleaned_str = ''.join(filter(str.isdigit, amount_str))\n",
    "        amount_numeric = int(cleaned_str) * 100000\n",
    "    elif 'Thou' in amount_str:\n",
    "        cleaned_str = ''.join(filter(str.isdigit, amount_str))\n",
    "        amount_numeric = int(cleaned_str) * 1000 \n",
    "    elif 'Hund' in amount_str:\n",
    "        cleaned_str = ''.join(filter(str.isdigit, amount_str))\n",
    "        amount_numeric = int(cleaned_str) * 100\n",
    "    else:\n",
    "        amount_numeric = amount_str\n",
    "    return int(amount_numeric)\n",
    "\n",
    "df['Total Assets'] = df['Total Assets'].apply(preprocess_amount)\n",
    "df['Liabilities'] = df['Liabilities'].apply(preprocess_amount)\n",
    "df_test['Total Assets'] = df_test['Total Assets'].apply(preprocess_amount)\n",
    "df_test['Liabilities'] = df_test['Liabilities'].apply(preprocess_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2059.000000</td>\n",
       "      <td>2.059000e+03</td>\n",
       "      <td>2.059000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.777562</td>\n",
       "      <td>1.155991e+08</td>\n",
       "      <td>2.159068e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.762183</td>\n",
       "      <td>4.922465e+08</td>\n",
       "      <td>2.048612e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.500000e+06</td>\n",
       "      <td>4.850000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>1.800000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000e+07</td>\n",
       "      <td>8.900000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.267000e+10</td>\n",
       "      <td>8.810000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Criminal Case  Total Assets   Liabilities\n",
       "count    2059.000000  2.059000e+03  2.059000e+03\n",
       "mean        1.777562  1.155991e+08  2.159068e+07\n",
       "std         4.762183  4.922465e+08  2.048612e+08\n",
       "min         0.000000  0.000000e+00  0.000000e+00\n",
       "25%         0.000000  9.500000e+06  4.850000e+04\n",
       "50%         0.000000  2.000000e+07  1.800000e+06\n",
       "75%         2.000000  8.000000e+07  8.900000e+06\n",
       "max        87.000000  1.267000e+10  8.810000e+09"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_too_dummy = ['Party','state']\n",
    "d = df.drop(['Education'],axis = 'columns')\n",
    "d = pd.get_dummies(d,columns = columns_too_dummy, drop_first=True)\n",
    "df_test = pd.get_dummies(df_test,columns = columns_too_dummy, drop_first=True)\n",
    "X_train = d\n",
    "y_train = df['Education']\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train[['Total Assets', 'Liabilities', 'Criminal Case']] = scaler.fit_transform(X_train[['Total Assets', 'Liabilities', 'Criminal Case']])\n",
    "df_test[['Total Assets', 'Liabilities', 'Criminal Case']] = scaler.transform(df_test[['Total Assets', 'Liabilities', 'Criminal Case']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation for each column\n",
    "mean_cc = X_train['Criminal Case'].mean()\n",
    "std_cc = X_train['Criminal Case'].std()\n",
    "\n",
    "mean_assets = X_train['Total Assets'].mean()\n",
    "std_assets = X_train['Total Assets'].std()\n",
    "\n",
    "mean_liabilities = X_train['Liabilities'].mean()\n",
    "std_liabilities = X_train['Liabilities'].std()\n",
    "\n",
    "# Binarize each column into four new columns based on value ranges\n",
    "X_train['Criminal Case < mean-std'] = np.where(X_train['Criminal Case'] < (mean_cc - std_cc), 1, 0)\n",
    "X_train['Criminal Case mean-std to mean'] = np.where((X_train['Criminal Case'] >= (mean_cc - std_cc)) & (X_train['Criminal Case'] < mean_cc), 1, 0)\n",
    "X_train['Criminal Case mean to mean+std'] = np.where((X_train['Criminal Case'] >= mean_cc) & (X_train['Criminal Case'] < (mean_cc + std_cc)), 1, 0)\n",
    "X_train['Criminal Case > mean+std'] = np.where(X_train['Criminal Case'] >= (mean_cc + std_cc), 1, 0)\n",
    "\n",
    "X_train['Total Assets < mean-std'] = np.where(X_train['Total Assets'] < (mean_assets - std_assets), 1, 0)\n",
    "X_train['Total Assets mean-std to mean'] = np.where((X_train['Total Assets'] >= (mean_assets - std_assets)) & (X_train['Total Assets'] < mean_assets), 1, 0)\n",
    "X_train['Total Assets mean to mean+std'] = np.where((X_train['Total Assets'] >= mean_assets) & (X_train['Total Assets'] < (mean_assets + std_assets)), 1, 0)\n",
    "X_train['Total Assets > mean+std'] = np.where(X_train['Total Assets'] >= (mean_assets + std_assets), 1, 0)\n",
    "\n",
    "X_train['Liabilities < mean-std'] = np.where(X_train['Liabilities'] < (mean_liabilities - std_liabilities), 1, 0)\n",
    "X_train['Liabilities mean-std to mean'] = np.where((X_train['Liabilities'] >= (mean_liabilities - std_liabilities)) & (X_train['Liabilities'] < mean_liabilities), 1, 0)\n",
    "X_train['Liabilities mean to mean+std'] = np.where((X_train['Liabilities'] >= mean_liabilities) & (X_train['Liabilities'] < (mean_liabilities + std_liabilities)), 1, 0)\n",
    "X_train['Liabilities > mean+std'] = np.where(X_train['Liabilities'] >= (mean_liabilities + std_liabilities), 1, 0)\n",
    "\n",
    "# Drop the original columns\n",
    "X_train.drop(['Criminal Case', 'Total Assets', 'Liabilities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation for each column\n",
    "mean_cc = df_test['Criminal Case'].mean()\n",
    "std_cc = df_test['Criminal Case'].std()\n",
    "\n",
    "mean_assets = df_test['Total Assets'].mean()\n",
    "std_assets = df_test['Total Assets'].std()\n",
    "\n",
    "mean_liabilities = df_test['Liabilities'].mean()\n",
    "std_liabilities = df_test['Liabilities'].std()\n",
    "\n",
    "# Binarize each column into four new columns based on value ranges\n",
    "df_test['Criminal Case < mean-std'] = np.where(df_test['Criminal Case'] < (mean_cc - std_cc), 1, 0)\n",
    "df_test['Criminal Case mean-std to mean'] = np.where((df_test['Criminal Case'] >= (mean_cc - std_cc)) & (df_test['Criminal Case'] < mean_cc), 1, 0)\n",
    "df_test['Criminal Case mean to mean+std'] = np.where((df_test['Criminal Case'] >= mean_cc) & (df_test['Criminal Case'] < (mean_cc + std_cc)), 1, 0)\n",
    "df_test['Criminal Case > mean+std'] = np.where(df_test['Criminal Case'] >= (mean_cc + std_cc), 1, 0)\n",
    "\n",
    "df_test['Total Assets < mean-std'] = np.where(df_test['Total Assets'] < (mean_assets - std_assets), 1, 0)\n",
    "df_test['Total Assets mean-std to mean'] = np.where((df_test['Total Assets'] >= (mean_assets - std_assets)) & (df_test['Total Assets'] < mean_assets), 1, 0)\n",
    "df_test['Total Assets mean to mean+std'] = np.where((df_test['Total Assets'] >= mean_assets) & (df_test['Total Assets'] < (mean_assets + std_assets)), 1, 0)\n",
    "df_test['Total Assets > mean+std'] = np.where(df_test['Total Assets'] >= (mean_assets + std_assets), 1, 0)\n",
    "\n",
    "df_test['Liabilities < mean-std'] = np.where(df_test['Liabilities'] < (mean_liabilities - std_liabilities), 1, 0)\n",
    "df_test['Liabilities mean-std to mean'] = np.where((df_test['Liabilities'] >= (mean_liabilities - std_liabilities)) & (df_test['Liabilities'] < mean_liabilities), 1, 0)\n",
    "df_test['Liabilities mean to mean+std'] = np.where((df_test['Liabilities'] >= mean_liabilities) & (df_test['Liabilities'] < (mean_liabilities + std_liabilities)), 1, 0)\n",
    "df_test['Liabilities > mean+std'] = np.where(df_test['Liabilities'] >= (mean_liabilities + std_liabilities), 1, 0)\n",
    "\n",
    "# Drop the original columns\n",
    "df_test.drop(['Criminal Case', 'Total Assets', 'Liabilities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vlskris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=15.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vlskris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "1080 fits failed out of a total of 2160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1080 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vlskris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\vlskris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vlskris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n",
      "    self._update_class_log_prior(class_prior=class_prior)\n",
      "  File \"c:\\Users\\vlskris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 590, in _update_class_log_prior\n",
      "    raise ValueError(\"Number of priors must match number of classes.\")\n",
      "ValueError: Number of priors must match number of classes.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\vlskris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.20006385 0.0981158         nan        nan 0.20006385 0.0981158\n",
      "        nan        nan 0.20006385 0.0981158         nan        nan\n",
      " 0.20006385 0.0981158         nan        nan 0.20006385 0.0981158\n",
      "        nan        nan 0.10575057 0.10575057        nan        nan\n",
      " 0.1990833  0.10215983        nan        nan 0.1990833  0.10215983\n",
      "        nan        nan 0.1990833  0.10215983        nan        nan\n",
      " 0.1990833  0.10215983        nan        nan 0.1990833  0.10215983\n",
      "        nan        nan 0.10575057 0.10575057        nan        nan\n",
      " 0.20344511 0.11982004        nan        nan 0.20344511 0.11982004\n",
      "        nan        nan 0.20344511 0.11982004        nan        nan\n",
      " 0.20344511 0.11982004        nan        nan 0.20344511 0.11982004\n",
      "        nan        nan 0.10575057 0.10575057        nan        nan\n",
      " 0.19855168 0.1574414         nan        nan 0.19855168 0.1574414\n",
      "        nan        nan 0.19855168 0.1574414         nan        nan\n",
      " 0.19855168 0.1574414         nan        nan 0.19855168 0.1574414\n",
      "        nan        nan 0.10575057 0.10575057        nan        nan\n",
      " 0.20167011 0.17745893        nan        nan 0.20167011 0.17745893\n",
      "        nan        nan 0.20167011 0.17745893        nan        nan\n",
      " 0.20167011 0.17745893        nan        nan 0.20167011 0.17745893\n",
      "        nan        nan 0.10575057 0.10575057        nan        nan\n",
      " 0.20430706 0.20802074        nan        nan 0.20430706 0.20802074\n",
      "        nan        nan 0.20430706 0.20802074        nan        nan\n",
      " 0.20430706 0.20802074        nan        nan 0.20430706 0.20802074\n",
      "        nan        nan 0.10575057 0.10575057        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 5.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    'binarize': [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    'fit_prior': [True, False],\n",
    "    'class_prior': [None, [0.3, 0.7]]\n",
    "}\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "grid_search = GridSearchCV(bnb, param_grid, cv=15, scoring='f1_weighted')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for 'ID' column\n",
    "df_id = pd.DataFrame({'ID': df_test1['ID']})\n",
    "\n",
    "# Create DataFrame for 'Education' column with predictions\n",
    "df_education = pd.DataFrame({'Education':grid_search.predict(df_test) })\n",
    "\n",
    "# Concatenate 'ID' and 'Education' DataFrames\n",
    "df_result = pd.concat([df_id, df_education], axis=1)\n",
    "df_result.to_csv('output_final_kaggle.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
